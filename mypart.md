# 糖尿病诊断模型训练与分析完整报告（增强版）
要让参考文献和对应的模型内容精准对应，**最佳方式是采用** **上标引用格式**，在提及模型的位置标注文献序号，文末统一列出参考文献列表。

以下是修改后的完整版本，包含**行内引用标注**和**规范参考文献列表**：

### 模型选型与训练

#### 模型选取
基于任务特性和数据特点，本研究选取了10种具有代表性的机器学习模型进行全面对比实验，以探寻最优解决方案。

| 模型类别         | 具体模型名称                                                                                                                                   |
| ---------------- | ---------------------------------------------------------------------------------------------------------------------------------------------- |
| 传统机器学习模型 | 随机森林（Random Forest） |
| 集成学习模型     | XGBoost<sup>[3]</sup>、LightGBM<sup>[4]</sup>、CatBoost<sup>[5]</sup>（树基集成模型，适配结构化数据，梯度提升框架）                            |
| 神经网络         | 多层感知机（MLP，简单深度学习模型，用于对比传统方法）<sup>[2]</sup>                                                                            |

传统机器学习模型的理论基础均源自经典统计学习框架<sup>[1]</sup>，集成学习模型则是在梯度提升树的基础上进行了工程优化与算法改进。

#### 模型训练与核心参数
为确保模型性能，所有模型均在统一的5折交叉验证框架下进行训练。以下为实验中使用的三种主流集成学习模型的核心超参数配置。

| 参数 (Parameter)          | CatBoost<sup>[5]</sup>                                   | LightGBM<sup>[4]</sup>                    | XGBoost<sup>[3]</sup>                     |
| ------------------------- | -------------------------------------------------------- | ----------------------------------------- | ----------------------------------------- |
| **任务类型**              | `task_type`: "GPU"                                       | N/A                                       | N/A                                       |
| **目标函数**              | `loss_function`: "Logloss"                               | `objective`: "binary"                     | `objective`: "binary:logistic"            |
| **评估指标**              | `eval_metric`: "AUC"                                     | N/A (自动使用目标函数的默认指标)          | N/A (自动使用目标函数的默认指标)          |
| **迭代次数**              | `iterations`: 4000                                       | `n_estimators`: 200                       | `n_estimators`: 200                       |
| **学习率**                | `learning_rate`: 0.05                                    | `learning_rate`: 0.03                     | `learning_rate`: 0.03                     |
| **树深度**                | `depth`: 6                                               | `num_leaves`: 64 (叶节点数，与深度相关)   | `max_depth`: 6                            |
| **正则化**                | `l2_leaf_reg`: 6                                         | N/A                                       | N/A                                       |
| **采样策略**              | `bootstrap_type`: "Bayesian", `bagging_temperature`: 0.8 | `subsample`: 0.8, `colsample_bytree`: 0.8 | `subsample`: 0.8, `colsample_bytree`: 0.8 |
| **早停/叶节点最小样本数** | `min_data_in_leaf`: 50                                   | N/A                                       | N/A                                       |
| **随机种子**              | `random_seed`: 42                                        | `random_state`: 42                        | `random_state`: 42                        |
| **其他**                  | `random_strength`: 1.0, `verbose`: 200                   | N/A                                       | N/A                                       |

---
### 参考文献
[1] Hastie T, Tibshirani R, Friedman J H. *The Elements of Statistical Learning: Data Mining, Inference, and Prediction* (2nd ed.)[M]. Springer, 2009.
[2] Bishop C M. *Pattern Recognition and Machine Learning*[M]. Springer, 2006.
[3] Chen T, Guestrin C. Xgboost: A scalable tree boosting system[C]//Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 2016: 785-794.
[4] Ke G, Meng Q, Finley T, et al. Lightgbm: A highly efficient gradient boosting decision tree[J]. Advances in Neural Information Processing Systems, 2017, 30: 3146-3154.
[5] Prokhorenkova L, Gusev G, Vorobev A, et al. CatBoost: unbiased boosting with categorical features[J]. Advances in Neural Information Processing Systems, 2018, 31: 6638-6648.

---

### 训练过程

**单模型训练**：
   
所有模型均基于训练子集训练，验证子集评估性能  
验证集和训练集按照2:8的比例分割，并随机打乱，减少因顺序带来的误差  
CatBoost训练过程中启用早停策略避免过拟合，最终在约2507轮迭代时达到最优性能。

**模型集成**：
设计两种融合策略，基于CatBoost和LightGBM的预测结果进行集成：  
1. 排名概率融合：对预测概率进行排名后加权融合（权重`k=0.4-0.8`）  
2. 归一化融合：先对预测概率归一化（`min-max`标准化），再加权融合，消除不同模型输出尺度差异。

## 四、特征重要性分析
基于CatBoost模型的特征重要性评估结果，绘制横向条形图如下：

![CatBoost特征重要性图](catboost_feature_importance.png)

关键特征重要性排名及得分如下表所示：

| 特征名称                              | 重要性得分 | 特征类别       |
| ------------------------------------- | ---------- | -------------- |
| physical_activity_minutes_per_week    | 29.6856    | 生活习惯特征   |
| family_history_diabetes               | 25.4918    | 病史特征       |
| age                                   | 10.7842    | 人口统计学特征 |
| triglycerides（甘油三酯）             | 7.3904     | 生理指标特征   |
| bmi（体重指数）                       | 3.8019     | 生理指标特征   |
| ldl_cholesterol（低密度脂蛋白胆固醇） | 3.0498     | 生理指标特征   |
| cholesterol_total（总胆固醇）         | 2.7646     | 生理指标特征   |
| heart_rate（心率）                    | 2.4463     | 生理指标特征   |
| systolic_bp（收缩压）                 | 2.3437     | 生理指标特征   |
| diet_score（饮食评分）                | 2.3154     | 生活习惯特征   |

> 特征类别这一列 删掉

**分析结论**：
1. 每周体育锻炼分钟数是最重要的特征，说明生活习惯对糖尿病诊断的影响显著；
2. 糖尿病家族史排名第二，验证了遗传因素在糖尿病发病中的核心作用；
3. 年龄、甘油三酯、BMI等生理相关特征也具有较高重要性，与医学常识一致；
4. 高血压病史和心血管病史重要性极低，可能与数据中这两类特征的分布或关联性较弱有关。

## 五、模型性能评估与对比

### （一）单模型性能全面对比

所有模型最优版本的性能指标如下表所示：

| 模型名称              | 准确率 | 精确率 | 召回率 | F1分数 | ROC AUC |
| --------------------- | ------ | ------ | ------ | ------ | ------- |
| CatBoost              | 0.6835 | 0.7063 | 0.8427 | 0.7685 | 0.7258  |
| LightGBM              | 0.6818 | 0.7027 | 0.8485 | 0.7687 | 0.7230  |
| XGBoost               | 0.6764 | 0.6939 | 0.8602 | 0.7682 | 0.7156  |
| Random Forest         | 0.6661 | 0.6785 | 0.8823 | 0.7671 | 0.6993  |
| Neural Network（MLP） | 0.6656 | 0.6844 | 0.8602 | 0.7623 | 0.6960  |

**核心结论**：
1. 树基集成模型（CatBoost、LightGBM、XGBoost）全面领先于传统模型和神经网络，体现了集成学习在结构化数据分类任务中的优势；
2. CatBoost综合性能最优：准确率（0.6835）、精确率（0.7063）、ROC AUC（0.7258）均为最高；
3. LightGBM在F1分数上略胜一筹（0.7687），平衡了精确率和召回率；
4. 随机森林召回率最高（0.8823），适合对阳性样本识别要求高的场景（如疾病筛查，优先避免漏诊）；
5. 其他常见机器学习事实上在早期对模型的探索中已经有过尝试，表现并不会优于随机森林或者是多层感知机，因此在这里不作讨论

### 关键实验操作对比分析

1. **分箱操作影响**：无分箱与不同分箱策略的性能对比（以CatBoost为例）：

| 分箱箱数    | 分箱策略    | 准确率 | 精确率 | 召回率 | F1分数 | ROC AUC |
| ----------- | ----------- | ------ | ------ | ------ | ------ | ------- |
| -（无分箱） | -（无分箱） | 0.6834 | 0.7062 | 0.8427 | 0.7684 | 0.7258  |
| 5           | uniform     | 0.6532 | 0.6681 | 0.8818 | 0.7602 | 0.6779  |
| 10          | uniform     | 0.6649 | 0.6861 | 0.8525 | 0.7603 | 0.6963  |
| 20          | quantile    | 0.6681 | 0.6898 | 0.8498 | 0.7614 | 0.7028  |

**可视化对比**：绘制无分箱与分箱（20-quantile）的模型训练迭代曲线（AUC收敛曲线）：

![无分箱迭代曲线](res/catboost_auc_convergence_curve.png)
![有分箱迭代曲线](res/catboost_new_auc_convergence_curve.png)

**结论**：
- 无分箱时模型性能最优，分箱操作导致特征信息损失；
- 分箱策略中，`quantile`（等频）优于`uniform`（等距）；
- 分箱后模型训练速度加快（迭代轮次减少），但性能下降，该数据集无需分箱处理。

2. **决策阈值（ALPHA）影响**：对比ALPHA=0.4和ALPHA=0.6时的模型性能（以核心模型为例）：

| 模型名称 | ALPHA=0.4 - 准确率 | ALPHA=0.4 - 精确率 | ALPHA=0.4 - 召回率 | ALPHA=0.4 - F1分数 | ALPHA=0.6 - 准确率 | ALPHA=0.6 - 精确率 | ALPHA=0.6 - 召回率 | ALPHA=0.6 - F1分数 |
| -------- | ------------------ | ------------------ | ------------------ | ------------------ | ------------------ | ------------------ | ------------------ | ------------------ |
| CatBoost | 0.6684             | 0.6650             | 0.9430             | 0.7800             | 0.6654             | 0.7609             | 0.6754             | 0.7156             |
| LightGBM | 0.6651             | 0.6610             | 0.9498             | 0.7795             | 0.6643             | 0.7604             | 0.6738             | 0.7145             |
| XGBoost  | 0.6578             | 0.6534             | 0.9606             | 0.7777             | 0.6570             | 0.7561             | 0.6638             | 0.7070             |

**结论**：
- ALPHA=0.4时模型更均衡，召回率大幅提升（如CatBoost召回率0.9430 vs 0.6754），F1分数更优；
- ALPHA=0.6时精确率提升，但召回率下降，适合对假阳性要求严格的场景。

3. **集成策略对比**：排名概率融合与归一化融合的性能对比(ALPHA = 0.5)：

| 集成策略              | 准确率 | 精确率 | 召回率 | F1分数 | ROC AUC |
| --------------------- | ------ | ------ | ------ | ------ | ------- |
| 排名概率融合（k=0.8） | 0.6743 | 0.7480 | 0.7200 | 0.7337 | 0.7254  |
| 归一化融合（k=0.8）   | 0.6742 | 0.6740 | 0.9245 | 0.7796 | 0.7254  |
| 单一CatBoost模型      | 0.6835 | 0.7063 | 0.8427 | 0.7685 | 0.7258  |

**结论**：
归一化融合优于排名概率融合，归一化后召回率大幅提升（0.9245 vs 0.7200），F1分数接近单一最优模型，集成模型稳定性更强。  
但是在精确率上是排名概率融合更为优秀

4. **交叉验证作用**：对比5折交叉验证与单一划分训练的性能（以CatBoost为例）：

| 评估指标 | 5折交叉验证 | 单一划分训练 | 差异（交叉-单一） |
| -------- | ----------- | ------------ | ----------------- |
| 准确率   | 0.6833      | 0.6829       | +0.0004           |
| 精确率   | 0.7060      | 0.7057       | +0.0003           |
| 召回率   | 0.8428      | 0.8427       | +0.0001           |
| F1分数   | 0.7684      | 0.7681       | +0.0003           |
| ROC AUC  | 0.7258      | 0.7252       | +0.0006           |

**结论**：交叉验证对模型性能提升较为有限。

# 模型集成中权重参数 k 的敏感性分析报告

## 一、分析背景与目的

在机器学习模型集成中，权重参数 `k` 用于平衡不同基模型（如 CatBoost 和 LightGBM）在最终预测中的贡献度。其值直接影响集成模型的综合性能。

本分析旨在通过对比两种不同集成策略（未归一化集成与归一化集成）下，权重 `k` 的变化对模型关键性能指标（准确率、精确率、召回率、F1 分数、ROC AUC）的影响，从而找到最优的权重配置，并揭示集成策略本身的优劣。

## 二、数据与方法

### （一）数据
分析基于两个性能对比表：
1.  **表1：不同k值（未归一化集成模型）性能对比表**：展示了直接对模型预测概率进行加权融合时的性能。
2.  **表2：不同k值（归一化集成模型）性能对比表**：展示了先对各模型预测概率进行 Min-Max 归一化，再进行加权融合时的性能。

### （二）方法
1.  **横向对比**：在同一种集成策略下，分析 `k` 值从 0.2 到 0.8 变化时，各项性能指标的波动趋势和稳定性。
2.  **纵向对比**：在相同 `k` 值下，对比未归一化集成与归一化集成的性能差异，评估归一化操作的价值。
3.  **最优值选择**：根据 F1 分数（综合评价指标）和 ROC AUC（模型区分能力指标），确定每种策略下的最优 `k` 值。

#### 性能指标随 k 值的变化趋势

| k值  | 准确率 | 精确率 | 召回率 | F1 分数 | ROC AUC |
| :--- | :----- | :----- | :----- | :------ | :------ |
| 0.4  | 0.6740 | 0.7476 | 0.7200 | 0.7336  | 0.7248  |
| 0.5  | 0.6742 | 0.7478 | 0.7202 | 0.7337  | 0.7251  |
| 0.6  | 0.6742 | 0.7478 | 0.7203 | 0.7338  | 0.7253  |
| 0.7  | 0.6742 | 0.7479 | 0.7199 | 0.7337  | 0.7254  |
| 0.8  | 0.6743 | 0.7480 | 0.7200 | 0.7337  | 0.7254  |


| k值  | 准确率 | 精确率 | 召回率 | F1 分数 | ROC AUC |
| :--- | :----- | :----- | :----- | :------ | :------ |
| 0.2  | 0.6758 | 0.6778 | 0.9149 | 0.7787  | 0.7240  |
| 0.3  | 0.6756 | 0.6771 | 0.9167 | 0.7789  | 0.7244  |
| 0.4  | 0.6751 | 0.6763 | 0.9182 | 0.7789  | 0.7248  |
| 0.5  | 0.6746 | 0.6755 | 0.9197 | 0.7789  | 0.7251  |
| 0.6  | 0.6747 | 0.6752 | 0.9214 | 0.7793  | 0.7253  |
| 0.7  | 0.6745 | 0.6745 | 0.9233 | 0.7795  | 0.7254  |
| 0.8  | 0.6742 | 0.6740 | 0.9245 | 0.7796  | 0.7254  |

为了直观对比，我们选取 `k=0.8` 时的性能进行比较：

| 策略             | k值  | 准确率 | 精确率 | 召回率 | F1 分数    | ROC AUC |
| :--------------- | :--- | :----- | :----- | :----- | :--------- | :------ |
| **未归一化集成** | 0.8  | 0.6743 | 0.7480 | 0.7200 | **0.7337** | 0.7254  |
| **归一化集成**   | 0.8  | 0.6742 | 0.6740 | 0.9245 | **0.7796** | 0.7254  |

1.  **归一化集成策略显著优于未归一化策略**：通过对基模型的预测概率进行归一化，可以有效平衡模型间的贡献，大幅提升集成模型的 F1 分数，这是本次分析中最重要的发现。
2.  **权重 k 的选择具有策略依赖性**：
    - 在**未归一化**策略下，`k` 值的影响很小，模型性能稳定，选择范围宽松。
    - 在**归一化**策略下，`k` 值是一个重要的可调参数，通过调整它可以在精确率和召回率之间找到最佳平衡点。
3.  **最优权重配置**：对于采用归一化集成策略的模型，将 CatBoost 的权重 `k` 设置为 **0.8** 可以获得最高的 F1 分数（0.7796）和 ROC AUC（0.7254），是本次实验的最优配置。

### （三）模型缺陷与原因分析
所有模型的准确率均未突破70%，核心原因如下：
1. **数据特性**：数据离散化程度高，部分特征与目标变量关联性弱，难以挖掘有效规律；
2. **类别不平衡**：阳性样本占比过高（62.33%），模型易偏向预测阳性，影响准确率；
3. **特征限制**：缺乏强相关性生物标志物特征（如空腹血糖值、糖化血红蛋白等），现有特征对糖尿病诊断的区分度有限；
4. **模型上限**：结构化数据的特征表达能力有限，传统机器学习模型难以捕捉复杂非线性关系。

## 六、最终预测与提交
### （一）最终模型选择
采用CatBoost和LightGBM的归一化集成模型（权重k=0.8），决策阈值ALPHA=0.4，具体流程如下：
1. 分别用CatBoost和LightGBM对测试集进行预测，得到预测概率；
2. 对两种模型的预测概率进行`min-max`归一化；
3. 按k=0.8（CatBoost权重）和1-k=0.2（LightGBM权重）加权融合，得到最终预测概率；
4. 以ALPHA=0.4为阈值，将预测概率转换为二分类结果（0/1）。

### （二）提交结果
生成最终预测文件`submission.csv`，包含id和diagnosed_diabetes两列，提交至Kaggle平台后，最终得分为0.63399，与验证集性能基本一致，验证了模型的泛化能力。

测试集预测结果前5条示例：

| id     | diagnosed_diabetes |
| ------ | ------------------ |
| 700000 | 1                  |
| 700001 | 1                  |
| 700002 | 1                  |
| 700003 | 0                  |
| 700004 | 1                  |

## 七、总结与展望
### （一）项目核心结论
1. **模型选型**：CatBoost是该任务的最优单一模型，集成模型（CatBoost+LightGBM归一化融合）稳定性更强，适合实际应用；
2. **关键参数**：决策阈值ALPHA=0.4更适合糖尿病筛查场景（优先保证召回率，减少漏诊），分箱操作对当前数据集无效；
3. **数据价值**：完整的特征数据（而非筛选后的少量特征）能显著提升模型性能，特征工程中应优先保留更多有效信息。

### （二）改进方向与展望
1. **数据层面**：
   - 补充强相关性生物标志物特征（如空腹血糖、糖化血红蛋白、胰岛素水平等）；
   - 优化数据采集质量，减少特征离散化影响，增加样本多样性；
   - 采用过采样、欠采样或SMOTE等方法处理类别不平衡问题。
2. **模型层面**：
   - 尝试更复杂的集成策略（如堆叠集成，Stacking），结合多个基模型的优势；
   - 引入注意力机制，增强关键特征的权重，提升模型可解释性；
   - 尝试深度学习模型（如TabNet、DeepFM），适配结构化数据的复杂关系。
